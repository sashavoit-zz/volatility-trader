{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1c04b9a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c04b9a8",
    "outputId": "61e276fe-2388-4914-fd4d-2a1fe0e3509c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tsai in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (22.0.3)\n",
      "Requirement already satisfied: fastai>=2.5.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (2.5.6)\n",
      "Requirement already satisfied: torch<1.11,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (1.10.2)\n",
      "Requirement already satisfied: pyts>=0.12.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (0.12.0)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (0.9.0)\n",
      "Requirement already satisfied: nbformat>=5.1.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (5.1.3)\n",
      "Requirement already satisfied: psutil>=5.4.8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (5.9.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tsai) (21.3)\n",
      "Requirement already satisfied: fastcore<1.5,>=1.3.27 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (1.0.2)\n",
      "Requirement already satisfied: spacy<4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (3.2.4)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (1.0.2)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (6.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (3.4.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (2.25.1)\n",
      "Requirement already satisfied: pillow>6.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (8.2.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (0.11.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (1.2.4)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (0.0.5)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fastai>=2.5.3->tsai) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from imbalanced-learn>=0.8.0->tsai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from imbalanced-learn>=0.8.0->tsai) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from imbalanced-learn>=0.8.0->tsai) (3.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nbformat>=5.1.3->tsai) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nbformat>=5.1.3->tsai) (5.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nbformat>=5.1.3->tsai) (4.4.0)\n",
      "Requirement already satisfied: jupyter-core in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nbformat>=5.1.3->tsai) (4.9.2)\n",
      "Requirement already satisfied: numba>=0.48.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyts>=0.12.0->tsai) (0.55.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch<1.11,>=1.7.0->tsai) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging->tsai) (2.4.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=5.1.3->tsai) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=5.1.3->tsai) (0.18.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from numba>=0.48.0->pyts>=0.12.0->tsai) (49.2.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from numba>=0.48.0->pyts>=0.12.0->tsai) (0.38.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (0.6.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (8.0.15)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (1.0.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (3.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (0.9.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (3.3.0)\n",
      "Requirement already satisfied: click<8.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (8.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (1.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (4.64.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (2.4.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<4->fastai>=2.5.3->tsai) (0.7.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->fastai>=2.5.3->tsai) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->fastai>=2.5.3->tsai) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->fastai>=2.5.3->tsai) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->fastai>=2.5.3->tsai) (4.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->fastai>=2.5.3->tsai) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->fastai>=2.5.3->tsai) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->fastai>=2.5.3->tsai) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas->fastai>=2.5.3->tsai) (2021.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->fastai>=2.5.3->tsai) (1.16.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<4->fastai>=2.5.3->tsai) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->spacy<4->fastai>=2.5.3->tsai) (2.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tsai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d305c",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b33bbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.713467</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>2.098651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.719555</td>\n",
       "      <td>0.036915</td>\n",
       "      <td>2.068303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.718412</td>\n",
       "      <td>0.048620</td>\n",
       "      <td>2.006872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.720527</td>\n",
       "      <td>0.095456</td>\n",
       "      <td>1.834030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.719023</td>\n",
       "      <td>0.023657</td>\n",
       "      <td>1.833023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PRICE      SIZE       vol\n",
       "0 -1.713467  0.000773  2.098651\n",
       "1 -1.719555  0.036915  2.068303\n",
       "2 -1.718412  0.048620  2.006872\n",
       "3 -1.720527  0.095456  1.834030\n",
       "4 -1.719023  0.023657  1.833023"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"5sec_intervals_no_na_normed.csv\")\n",
    "df = df[['PRICE', 'SIZE', 'vol']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2daf5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[:round(0.8 * len(df))].copy()\n",
    "test_data = df[train_data.iloc[-1].name+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31deb197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.713467</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>2.098651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.719555</td>\n",
       "      <td>0.036915</td>\n",
       "      <td>2.068303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.718412</td>\n",
       "      <td>0.048620</td>\n",
       "      <td>2.006872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.720527</td>\n",
       "      <td>0.095456</td>\n",
       "      <td>1.834030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.719023</td>\n",
       "      <td>0.023657</td>\n",
       "      <td>1.833023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-1.714687</td>\n",
       "      <td>-0.006404</td>\n",
       "      <td>1.818437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-1.718210</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>1.817190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1.716480</td>\n",
       "      <td>0.062125</td>\n",
       "      <td>1.818805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-1.717838</td>\n",
       "      <td>-0.020977</td>\n",
       "      <td>1.809160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.715703</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>1.787224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRICE      SIZE       vol\n",
       "0   -1.713467  0.000773  2.098651\n",
       "1   -1.719555  0.036915  2.068303\n",
       "2   -1.718412  0.048620  2.006872\n",
       "3   -1.720527  0.095456  1.834030\n",
       "4   -1.719023  0.023657  1.833023\n",
       "..        ...       ...       ...\n",
       "115 -1.714687 -0.006404  1.818437\n",
       "116 -1.718210  0.009351  1.817190\n",
       "117 -1.716480  0.062125  1.818805\n",
       "118 -1.717838 -0.020977  1.809160\n",
       "119 -1.715703  0.000706  1.787224\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1160b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.FloatTensor(train_data.to_numpy().tolist())\n",
    "test_data_normalized = torch.FloatTensor(test_data.to_numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d018f9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6298, -0.6214, -0.6266,  ...,  0.5650,  0.5892,  0.6046])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_normalized[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88860b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw, sl):\n",
    "    \"\"\"\n",
    "    tw: train_window\n",
    "    sl: sequence_length\n",
    "    \"\"\"\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw-sl):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        # Select the volatility column\n",
    "        train_label = input_data[i+tw:i+tw+sl, 2]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "train_window = 100\n",
    "pred_seq_len = 20\n",
    "\n",
    "# Prepare sequences\n",
    "train_sequence = create_inout_sequences(train_data.to_numpy(), train_window, pred_seq_len)\n",
    "test_sequence = create_inout_sequences(test_data.to_numpy(), train_window, pred_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b8917",
   "metadata": {},
   "source": [
    "# Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c1d4f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, batch_size):\n",
    "    \"\"\"\n",
    "    Generator that yields batches of data\n",
    "\n",
    "    Args:\n",
    "      x: input values\n",
    "      y: output values\n",
    "      batch_size: size of each batch\n",
    "    Yields:\n",
    "      batch_x: a batch of inputs of size at most batch_size\n",
    "      batch_y: a batch of outputs of size at most batch_size\n",
    "    \"\"\"\n",
    "    N = np.shape(x)[0]\n",
    "    assert N == np.shape(y)[0]\n",
    "    for i in range(0, N, batch_size):\n",
    "        batch_x = np.array(x[i : i + batch_size])\n",
    "        batch_y = np.array(y[i : i + batch_size])\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "87dd2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [t[0] for t in train_sequence]\n",
    "train_y = [t[1] for t in train_sequence]\n",
    "\n",
    "batches = get_batch(train_x, train_y, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "13ebff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_vars(xs, ys, gpu=False):\n",
    "    \"\"\"\n",
    "    Helper function to convert numpy arrays to pytorch tensors.\n",
    "    If GPU is used, move the tensors to GPU.\n",
    "\n",
    "    Args:\n",
    "      xs (float numpy tenosor): greyscale input\n",
    "      ys (int numpy tenosor): categorical labels\n",
    "      gpu (bool): whether to move pytorch tensor to GPU\n",
    "    Returns:\n",
    "      Variable(xs), Variable(ys)\n",
    "    \"\"\"\n",
    "    xs = torch.from_numpy(xs).float()\n",
    "    ys = torch.from_numpy(ys).long()\n",
    "    if gpu:\n",
    "        xs = xs.cuda()\n",
    "        ys = ys.cuda()\n",
    "    return Variable(xs), Variable(ys)\n",
    "\n",
    "\n",
    "def run_validation_step(\n",
    "    model,\n",
    "    criterion,\n",
    "    inputs,\n",
    "    labels,\n",
    "    batch_size,\n",
    "    args,\n",
    "    plotpath=None,\n",
    "    visualize=True,\n",
    "    downsize_input=False\n",
    "):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    losses = []\n",
    "    num_colours = np.shape(colours)[0]\n",
    "    for i, (xs, ys) in enumerate(get_batch(inputs, labels, batch_size)):\n",
    "        inputs, labels = get_torch_vars(xs, ys, args.gpu)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        losses.append(val_loss.data.item())\n",
    "\n",
    "        # _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "\n",
    "#     if plotpath:  # only plot if a path is provided\n",
    "#         plot(\n",
    "#             xs,\n",
    "#             ys,\n",
    "#             predicted.cpu().numpy(),\n",
    "#             colours,\n",
    "#             plotpath,\n",
    "#             visualize=visualize,\n",
    "#             compare_bilinear=downsize_input,\n",
    "#         )\n",
    "\n",
    "    val_loss = np.mean(losses)\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "        \n",
    "def train(args, model=None):\n",
    "    # Set the maximum number of threads to prevent crash in Teaching Labs\n",
    "    # TODO: necessary?\n",
    "    torch.set_num_threads(5)\n",
    "    # Numpy random seed\n",
    "    npr.seed(args.seed)\n",
    "\n",
    "    # Save directory\n",
    "    save_dir = \"outputs/\" + args.experiment_name\n",
    "\n",
    "    # LOAD THE COLOURS CATEGORIES\n",
    "    colours = np.load(args.colours, allow_pickle=True, encoding=\"bytes\")[0]\n",
    "    num_colours = np.shape(colours)[0]\n",
    "    # INPUT CHANNEL\n",
    "    num_in_channels = 1 if not args.downsize_input else 3\n",
    "    # LOAD THE MODEL\n",
    "    if model is None:\n",
    "        Net = globals()[args.model]\n",
    "        model = Net(args.kernel, args.num_filters, num_colours, num_in_channels)\n",
    "\n",
    "    # LOSS FUNCTION\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=args.learn_rate)\n",
    "\n",
    "    # DATA\n",
    "    print(\"Loading data...\")\n",
    "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
    "\n",
    "    print(\"Transforming data...\")\n",
    "    train_rgb, train_grey = process(x_train, y_train, downsize_input=args.downsize_input)\n",
    "    train_rgb_cat = get_rgb_cat(train_rgb, colours)\n",
    "    test_rgb, test_grey = process(x_test, y_test, downsize_input=args.downsize_input)\n",
    "    test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
    "\n",
    "    # Create the outputs folder if not created already\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print(\"Beginning training ...\")\n",
    "    if args.gpu:\n",
    "        cnn.cuda()\n",
    "    start = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    for epoch in range(args.epochs):\n",
    "        # Train the Model\n",
    "        model.train()  # Change model to 'train' mode\n",
    "        losses = []\n",
    "        for i, (xs, ys) in enumerate(get_batch(train_grey, train_rgb_cat, args.batch_size)):\n",
    "            images, labels = get_torch_vars(xs, ys, args.gpu)\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = compute_loss(\n",
    "                criterion, outputs, labels, batch_size=args.batch_size, num_colours=num_colours\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        val_loss, val_acc = run_validation_step(\n",
    "            model,\n",
    "            criterion,\n",
    "            test_grey,\n",
    "            test_rgb_cat,\n",
    "            args.batch_size,\n",
    "            colours,\n",
    "            save_dir + \"/test_%d.png\" % epoch,\n",
    "            args.visualize,\n",
    "            args.downsize_input,\n",
    "        )\n",
    "\n",
    "        time_elapsed = time.time() - start\n",
    "        valid_losses.append(val_loss)\n",
    "        valid_accs.append(val_acc)\n",
    "        print(\n",
    "            \"Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %.2f\"\n",
    "            % (epoch + 1, args.epochs, val_loss, val_acc, time_elapsed)\n",
    "        )\n",
    "\n",
    "    # Plot training curve\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
    "    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(save_dir + \"/training_curve.png\")\n",
    "\n",
    "    if args.checkpoint:\n",
    "        print(\"Saving model...\")\n",
    "        torch.save(model.state_dict(), args.checkpoint)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e0180",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e238f44",
   "metadata": {
    "id": "5e238f44"
   },
   "outputs": [],
   "source": [
    "# TCN IMPLEMENTATION\n",
    "\n",
    "# Bai, S., Kolter, J. Z., & Koltun, V. (2018). An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271.\n",
    "# Official TCN PyTorch implementation: https://github.com/locuslab/TCN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8988bb29",
   "metadata": {
    "id": "8988bb29"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Inputs have to have dimension (N, C_in, L_in)\"\"\"\n",
    "        y1 = self.tcn(inputs)  # input should have dimension (N, C, L)\n",
    "        o = self.linear(y1[:, :, -1])\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "pbl1joAlY2sj",
   "metadata": {
    "id": "pbl1joAlY2sj"
   },
   "outputs": [],
   "source": [
    "# Model that uses TCN\n",
    "\n",
    "class VolForecast(nn.Module):\n",
    "    def __init__(self, seq_len, input_size, output_size=1):\n",
    "        super(VolForecast, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.tcn = TCN(input_size=input_size, output_size=output_size, num_channels=8*[25], kernel_size=7, dropout=0.1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.tcn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ad91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the simple TCN block model\n",
    "\n",
    "train_window = 100\n",
    "pred_seq_len = 20\n",
    "\n",
    "args = AttrDict()\n",
    "args_dict = {\n",
    "    \"gpu\": False,\n",
    "    \"valid\": False,\n",
    "    \"checkpoint\": \"\",\n",
    "    \"sequence_len\": train_window,\n",
    "    \"output_size\": pred_seq_len,\n",
    "    \"model\": \"TCN_simple\",\n",
    "    \"kernel\": 3,\n",
    "    \"num_filters\": 32,\n",
    "    'learn_rate':0.001, \n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 50,\n",
    "    \"seed\": 0,\n",
    "    \"plot\": False,\n",
    "    \"experiment_name\": \"simple_TCN_volatility\",\n",
    "    \"visualize\": False,\n",
    "    \"downsize_input\": False,\n",
    "}\n",
    "args.update(args_dict)\n",
    " = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "59066ca8",
   "metadata": {
    "id": "59066ca8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "def get_data_single_horizon(file_name, seq_len, horizon, input_fields, output_fields, val_ratio=0.01):\n",
    "    # Get data from csv\n",
    "    df = pd.read_csv(file_name)\n",
    "    inputs = df_to_tensor(df[input_fields])\n",
    "    outputs = df_to_tensor(df[output_fields])\n",
    "    \n",
    "    # Group seq_len concecutive input points together, and horizon concecutive output vectors together\n",
    "    inputs = torch.stack([inputs[i:i - seq_len - horizon] for i in range(seq_len)], dim = 1)\n",
    "    outputs = outputs[seq_len + horizon:]\n",
    "\n",
    "    assert len(inputs) == len(outputs), f\"Input and output arrays have different lengths: {len(inputs)} \\= {len(outputs)}\"\n",
    "    \n",
    "    # Do train/validation split\n",
    "    val_len = math.ceil(val_ratio * len(inputs))\n",
    "    train_x = inputs[:-val_len].transpose(1,2)\n",
    "    train_y = outputs[:-val_len]\n",
    "    val_x = inputs[-val_len:].transpose(1,2)\n",
    "    val_y = outputs[-val_len:]\n",
    "\n",
    "    print(\"Train input dimension:\", train_x.shape)\n",
    "    print(\"Train output dimension:\", train_y.shape)\n",
    "    print(\"Validation input dimension:\", val_x.shape)\n",
    "    print(\"Validation output dimension:\", val_y.shape)\n",
    "\n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43beaa2a",
   "metadata": {
    "id": "43beaa2a"
   },
   "outputs": [],
   "source": [
    "from pandas.core.dtypes.cast import validate_numeric_casting\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, opts, train_x, train_y, val_x, val_y):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    batch_size = opts['batch_size']\n",
    "    validation_period = opts['validation_period']\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(opts['nepochs']):\n",
    "        # Sample batch input randomly\n",
    "        random_ids = np.random.randint(len(train_x), size=batch_size)\n",
    "        train_input = train_x[random_ids]\n",
    "        train_output = train_y[random_ids]        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(train_input), train_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses += [loss]\n",
    "\n",
    "        if (epoch+1) % validation_period == 0:\n",
    "\n",
    "            val_loss = loss_fn(model(val_x), val_y)\n",
    "            val_losses += [val_loss]\n",
    "  \n",
    "            print(f\"Epoch: {epoch + 1}, training loss: {loss}, validation loss: {val_loss}\")\n",
    "        else:\n",
    "            print(f\"Epoch: {epoch + 1}, training loss: {loss}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), './model')\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8c7a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.dtypes.cast import validate_numeric_casting\n",
    "import torch.optim as optim\n",
    "\n",
    "def train2(model, opts):\n",
    "    loss_function = nn.MSELoss()\n",
    "    batch_size = opts['batch_size']\n",
    "    epochs = opts['nepochs']\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for seq, labels in train_sequence:\n",
    "            optimizer.zero_grad()\n",
    "#             model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "#                             torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "            y_pred = model(seq)\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if i%25 == 1:\n",
    "            print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dfc2b22",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [25, 3, 7], but got 2-dimensional input of size [100, 3] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m VolForecast(seq_len\u001b[38;5;241m=\u001b[39mtrain_window ,input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, output_size\u001b[38;5;241m=\u001b[39mpred_seq_len)\n\u001b[1;32m      3\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_period\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mtrain2\u001b[0;34m(model, opts)\u001b[0m\n\u001b[1;32m     12\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#             model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#                             torch.zeros(1, 1, model.hidden_layer_size))\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m             y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m             single_loss \u001b[38;5;241m=\u001b[39m loss_function(y_pred, labels)\n\u001b[1;32m     19\u001b[0m             single_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36mVolForecast.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [83]\u001b[0m, in \u001b[0;36mTCN.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124;03m\"\"\"Inputs have to have dimension (N, C_in, L_in)\"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# input should have dimension (N, C, L)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(y1[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m o\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mTemporalConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mTemporalBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 48\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     res \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out \u001b[38;5;241m+\u001b[39m res)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1120\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1120\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:301\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:297\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    295\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    296\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight [25, 3, 7], but got 2-dimensional input of size [100, 3] instead"
     ]
    }
   ],
   "source": [
    "model = VolForecast(seq_len=train_window ,input_size=3, output_size=pred_seq_len)\n",
    "\n",
    "opts = {\n",
    "    \"nepochs\": 500,\n",
    "    \"batch_size\": 64,\n",
    "    \"validation_period\": 1000\n",
    "}\n",
    "\n",
    "train2(model, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "-ezI05mFiEiH",
   "metadata": {
    "id": "-ezI05mFiEiH"
   },
   "outputs": [],
   "source": [
    "def plot_model_performance_single_horizon(model, x, y, num_samples, horizon):\n",
    "  assert num_samples < len(x), f\"Too many samples: {num_samples}. Input size is only {len(x)}\"\n",
    "  pred = model(x[:num_samples])\n",
    "  reality = y[horizon:num_samples+horizon]\n",
    "\n",
    "  plt.plot(pred.detach().numpy(), 'r')\n",
    "  plt.plot(reality.detach().numpy(), 'b')\n",
    "\n",
    "# def plot_model_performance_multiple_horizons(model, x, y, num_samples, horizon):\n",
    "#   assert num_samples < len(x), f\"Too many samples: {num_samples}. Input size is only {len(x)}\"\n",
    "#   pred = model(x[:num_samples])[:, horizon-1]\n",
    "#   reality = y[:num_samples][:, horizon-1]\n",
    "\n",
    "#   plt.plot(pred.detach().numpy(), 'r')\n",
    "#   plt.plot(reality.detach().numpy(), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92af5f4",
   "metadata": {
    "id": "c92af5f4"
   },
   "outputs": [],
   "source": [
    "## Setting some params\n",
    "model=None\n",
    "seq_len=300\n",
    "horizon=50\n",
    "\n",
    "input_fields = ['PRICE', 'SIZE', 'vol']\n",
    "output_fields = ['vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "FF9Hkq3BHzPq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FF9Hkq3BHzPq",
    "outputId": "2fb1d515-9885-4242-96fb-d088e631b288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input dimension: torch.Size([571369, 3, 300])\n",
      "Train output dimension: torch.Size([571369, 1])\n",
      "Validation input dimension: torch.Size([5772, 3, 300])\n",
      "Validation output dimension: torch.Size([5772, 1])\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y = get_data_single_horizon('5sec_intervals_no_na_normed.csv', seq_len=seq_len, horizon=horizon, \n",
    "                                                         input_fields=input_fields, output_fields=output_fields, val_ratio=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3HnEgpbzWM0S",
   "metadata": {
    "id": "3HnEgpbzWM0S"
   },
   "outputs": [],
   "source": [
    "model=VolForecast(input_size=len(input_fields), seq_len=seq_len, horizon=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fdd7646",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fdd7646",
    "outputId": "60bced18-0bde-420d-c7b7-37430b5fcaa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, training loss: 0.46561405062675476\n",
      "Epoch: 2, training loss: 27.542495727539062\n",
      "Epoch: 3, training loss: 1.6271908283233643\n",
      "Epoch: 4, training loss: 1.0528066158294678\n",
      "Epoch: 5, training loss: 1.025953769683838\n",
      "Epoch: 6, training loss: 1.0483522415161133\n",
      "Epoch: 7, training loss: 0.7423053979873657\n",
      "Epoch: 8, training loss: 2.9472732543945312\n",
      "Epoch: 9, training loss: 0.7138708829879761\n",
      "Epoch: 10, training loss: 0.6462883353233337\n",
      "Epoch: 11, training loss: 0.9674425721168518\n",
      "Epoch: 12, training loss: 0.4953930377960205\n",
      "Epoch: 13, training loss: 0.38409215211868286\n",
      "Epoch: 14, training loss: 0.709173858165741\n",
      "Epoch: 15, training loss: 0.5367158651351929\n",
      "Epoch: 16, training loss: 0.33580198884010315\n",
      "Epoch: 17, training loss: 0.36139002442359924\n",
      "Epoch: 18, training loss: 0.6032704710960388\n",
      "Epoch: 19, training loss: 0.3713749051094055\n",
      "Epoch: 20, training loss: 0.33543550968170166\n",
      "Epoch: 21, training loss: 0.2532128691673279\n",
      "Epoch: 22, training loss: 0.1741548329591751\n",
      "Epoch: 23, training loss: 4.435169219970703\n",
      "Epoch: 24, training loss: 0.6078352332115173\n",
      "Epoch: 25, training loss: 0.20390884578227997\n",
      "Epoch: 26, training loss: 0.18510887026786804\n",
      "Epoch: 27, training loss: 5.682523727416992\n",
      "Epoch: 28, training loss: 1.7774733304977417\n",
      "Epoch: 29, training loss: 0.3913659453392029\n",
      "Epoch: 30, training loss: 0.2191825658082962\n",
      "Epoch: 31, training loss: 0.38581082224845886\n",
      "Epoch: 32, training loss: 0.23097582161426544\n",
      "Epoch: 33, training loss: 0.7511200904846191\n",
      "Epoch: 34, training loss: 0.126680389046669\n",
      "Epoch: 35, training loss: 0.08390839397907257\n",
      "Epoch: 36, training loss: 0.2913079261779785\n",
      "Epoch: 37, training loss: 0.12091932445764542\n",
      "Epoch: 38, training loss: 0.7829373478889465\n",
      "Epoch: 39, training loss: 0.07712384313344955\n",
      "Epoch: 40, training loss: 0.08379188179969788\n",
      "Epoch: 41, training loss: 0.09326861053705215\n",
      "Epoch: 42, training loss: 3.1920151710510254\n",
      "Epoch: 43, training loss: 0.29566383361816406\n",
      "Epoch: 44, training loss: 0.07314730435609818\n",
      "Epoch: 45, training loss: 0.06096590310335159\n",
      "Epoch: 46, training loss: 0.5201666355133057\n",
      "Epoch: 47, training loss: 0.0682658776640892\n",
      "Epoch: 48, training loss: 0.10766493529081345\n",
      "Epoch: 49, training loss: 0.4675038158893585\n",
      "Epoch: 50, training loss: 0.1429552435874939\n",
      "Epoch: 51, training loss: 5.534708499908447\n",
      "Epoch: 52, training loss: 0.21928417682647705\n",
      "Epoch: 53, training loss: 0.29886394739151\n",
      "Epoch: 54, training loss: 0.8484241962432861\n",
      "Epoch: 55, training loss: 0.13370144367218018\n",
      "Epoch: 56, training loss: 0.15529850125312805\n",
      "Epoch: 57, training loss: 0.4572778642177582\n",
      "Epoch: 58, training loss: 0.14309465885162354\n",
      "Epoch: 59, training loss: 0.49883565306663513\n",
      "Epoch: 60, training loss: 0.2252621352672577\n",
      "Epoch: 61, training loss: 0.6296305656433105\n",
      "Epoch: 62, training loss: 0.1854623556137085\n",
      "Epoch: 63, training loss: 0.07468906790018082\n",
      "Epoch: 64, training loss: 0.16379272937774658\n",
      "Epoch: 65, training loss: 0.7838847637176514\n",
      "Epoch: 66, training loss: 0.14656321704387665\n",
      "Epoch: 67, training loss: 1.5305639505386353\n",
      "Epoch: 68, training loss: 1.0517387390136719\n",
      "Epoch: 69, training loss: 0.12495492398738861\n",
      "Epoch: 70, training loss: 0.195842444896698\n",
      "Epoch: 71, training loss: 0.09075020998716354\n",
      "Epoch: 72, training loss: 0.18026623129844666\n",
      "Epoch: 73, training loss: 0.0711953267455101\n",
      "Epoch: 74, training loss: 0.08464875817298889\n",
      "Epoch: 75, training loss: 0.17731615900993347\n",
      "Epoch: 76, training loss: 0.5646161437034607\n",
      "Epoch: 77, training loss: 0.5227370858192444\n",
      "Epoch: 78, training loss: 0.14011099934577942\n",
      "Epoch: 79, training loss: 0.16843315958976746\n",
      "Epoch: 80, training loss: 0.07855797559022903\n",
      "Epoch: 81, training loss: 0.12004020810127258\n",
      "Epoch: 82, training loss: 0.25488799810409546\n",
      "Epoch: 83, training loss: 0.09336954355239868\n",
      "Epoch: 84, training loss: 0.1271720677614212\n",
      "Epoch: 85, training loss: 0.7582966685295105\n",
      "Epoch: 86, training loss: 0.10394079983234406\n",
      "Epoch: 87, training loss: 2.5516765117645264\n",
      "Epoch: 88, training loss: 0.16571475565433502\n",
      "Epoch: 89, training loss: 0.10104309767484665\n",
      "Epoch: 90, training loss: 0.2666476368904114\n",
      "Epoch: 91, training loss: 0.06868147850036621\n",
      "Epoch: 92, training loss: 0.12414814531803131\n",
      "Epoch: 93, training loss: 0.20783445239067078\n",
      "Epoch: 94, training loss: 0.09340827912092209\n",
      "Epoch: 95, training loss: 0.1435198038816452\n",
      "Epoch: 96, training loss: 0.24527432024478912\n",
      "Epoch: 97, training loss: 0.2950323522090912\n",
      "Epoch: 98, training loss: 0.0839238166809082\n",
      "Epoch: 99, training loss: 0.10003750026226044\n",
      "Epoch: 100, training loss: 0.09242231398820877\n",
      "Epoch: 101, training loss: 0.11065267771482468\n",
      "Epoch: 102, training loss: 0.9720754623413086\n",
      "Epoch: 103, training loss: 0.06764274090528488\n",
      "Epoch: 104, training loss: 0.053170785307884216\n",
      "Epoch: 105, training loss: 0.13624146580696106\n",
      "Epoch: 106, training loss: 0.08531311899423599\n",
      "Epoch: 107, training loss: 0.09852835536003113\n",
      "Epoch: 108, training loss: 0.4816123843193054\n",
      "Epoch: 109, training loss: 0.1373588591814041\n",
      "Epoch: 110, training loss: 5.55129337310791\n",
      "Epoch: 111, training loss: 0.23006220161914825\n",
      "Epoch: 112, training loss: 0.11490435898303986\n",
      "Epoch: 113, training loss: 0.3565128743648529\n",
      "Epoch: 114, training loss: 0.13845999538898468\n",
      "Epoch: 115, training loss: 0.1729278564453125\n",
      "Epoch: 116, training loss: 0.057700879871845245\n",
      "Epoch: 117, training loss: 0.3934547007083893\n",
      "Epoch: 118, training loss: 0.17586255073547363\n",
      "Epoch: 119, training loss: 0.08026110380887985\n",
      "Epoch: 120, training loss: 0.0790509283542633\n",
      "Epoch: 121, training loss: 0.1254872977733612\n",
      "Epoch: 122, training loss: 0.3955095112323761\n",
      "Epoch: 123, training loss: 4.57232666015625\n",
      "Epoch: 124, training loss: 0.160858154296875\n",
      "Epoch: 125, training loss: 0.06928961724042892\n",
      "Epoch: 126, training loss: 0.11537569761276245\n",
      "Epoch: 127, training loss: 0.0830245241522789\n",
      "Epoch: 128, training loss: 0.07878699153661728\n",
      "Epoch: 129, training loss: 0.09684856235980988\n",
      "Epoch: 130, training loss: 0.195005863904953\n",
      "Epoch: 131, training loss: 0.2954411208629608\n",
      "Epoch: 132, training loss: 0.07863832265138626\n",
      "Epoch: 133, training loss: 0.15245534479618073\n",
      "Epoch: 134, training loss: 0.31232741475105286\n",
      "Epoch: 135, training loss: 0.05255930498242378\n",
      "Epoch: 136, training loss: 0.10739535093307495\n",
      "Epoch: 137, training loss: 0.05278311297297478\n",
      "Epoch: 138, training loss: 0.05712609738111496\n",
      "Epoch: 139, training loss: 0.6540212035179138\n",
      "Epoch: 140, training loss: 0.15676259994506836\n",
      "Epoch: 141, training loss: 1.6226269006729126\n",
      "Epoch: 142, training loss: 2.4171464443206787\n",
      "Epoch: 143, training loss: 0.24969443678855896\n",
      "Epoch: 144, training loss: 0.16901865601539612\n",
      "Epoch: 145, training loss: 0.1311585158109665\n",
      "Epoch: 146, training loss: 0.18667727708816528\n",
      "Epoch: 147, training loss: 0.16504217684268951\n",
      "Epoch: 148, training loss: 0.3852460980415344\n",
      "Epoch: 149, training loss: 0.09061222523450851\n",
      "Epoch: 150, training loss: 0.29702627658843994\n",
      "Epoch: 151, training loss: 0.5121480226516724\n",
      "Epoch: 152, training loss: 0.1300109624862671\n",
      "Epoch: 153, training loss: 0.26961904764175415\n",
      "Epoch: 154, training loss: 0.07394123077392578\n",
      "Epoch: 155, training loss: 0.17350172996520996\n",
      "Epoch: 156, training loss: 0.1270710825920105\n",
      "Epoch: 157, training loss: 0.07703882455825806\n",
      "Epoch: 158, training loss: 1.5815277099609375\n",
      "Epoch: 159, training loss: 0.09069671481847763\n",
      "Epoch: 160, training loss: 0.11130785197019577\n",
      "Epoch: 161, training loss: 0.12744615972042084\n",
      "Epoch: 162, training loss: 0.17097172141075134\n",
      "Epoch: 163, training loss: 2.559480667114258\n",
      "Epoch: 164, training loss: 0.13504913449287415\n",
      "Epoch: 165, training loss: 0.04741667956113815\n",
      "Epoch: 166, training loss: 0.47110646963119507\n",
      "Epoch: 167, training loss: 0.38587287068367004\n",
      "Epoch: 168, training loss: 0.09795990586280823\n",
      "Epoch: 169, training loss: 0.1422785222530365\n",
      "Epoch: 170, training loss: 0.2775469422340393\n",
      "Epoch: 171, training loss: 0.13908107578754425\n",
      "Epoch: 172, training loss: 0.35533416271209717\n",
      "Epoch: 173, training loss: 0.3466435372829437\n",
      "Epoch: 174, training loss: 0.19812113046646118\n",
      "Epoch: 175, training loss: 0.26110178232192993\n",
      "Epoch: 176, training loss: 0.2963944673538208\n",
      "Epoch: 177, training loss: 0.18483828008174896\n",
      "Epoch: 178, training loss: 0.13409942388534546\n",
      "Epoch: 179, training loss: 0.0797477588057518\n",
      "Epoch: 180, training loss: 0.07768463343381882\n",
      "Epoch: 181, training loss: 0.07494543492794037\n",
      "Epoch: 182, training loss: 0.13945385813713074\n",
      "Epoch: 183, training loss: 0.1747528314590454\n",
      "Epoch: 184, training loss: 0.33397674560546875\n",
      "Epoch: 185, training loss: 2.1736066341400146\n",
      "Epoch: 186, training loss: 0.04888511821627617\n",
      "Epoch: 187, training loss: 0.09872960299253464\n",
      "Epoch: 188, training loss: 0.3389126658439636\n",
      "Epoch: 189, training loss: 5.610671043395996\n",
      "Epoch: 190, training loss: 0.11820021271705627\n",
      "Epoch: 191, training loss: 0.05250875651836395\n",
      "Epoch: 192, training loss: 0.21061229705810547\n",
      "Epoch: 193, training loss: 0.28830206394195557\n",
      "Epoch: 194, training loss: 0.3822151720523834\n",
      "Epoch: 195, training loss: 0.16593095660209656\n",
      "Epoch: 196, training loss: 0.15690791606903076\n",
      "Epoch: 197, training loss: 0.17669619619846344\n",
      "Epoch: 198, training loss: 0.26011162996292114\n",
      "Epoch: 199, training loss: 0.10714152455329895\n",
      "Epoch: 200, training loss: 0.1387556791305542\n",
      "Epoch: 201, training loss: 0.0752098485827446\n",
      "Epoch: 202, training loss: 1.4057034254074097\n",
      "Epoch: 203, training loss: 0.08482461422681808\n",
      "Epoch: 204, training loss: 0.056001074612140656\n",
      "Epoch: 205, training loss: 0.11079628020524979\n",
      "Epoch: 206, training loss: 0.15171180665493011\n",
      "Epoch: 207, training loss: 0.1316787451505661\n",
      "Epoch: 208, training loss: 0.08852261304855347\n",
      "Epoch: 209, training loss: 0.24508258700370789\n",
      "Epoch: 210, training loss: 0.08481714874505997\n",
      "Epoch: 211, training loss: 0.17452189326286316\n",
      "Epoch: 212, training loss: 0.44897493720054626\n",
      "Epoch: 213, training loss: 0.1364758014678955\n",
      "Epoch: 214, training loss: 1.9473930597305298\n",
      "Epoch: 215, training loss: 0.4146419167518616\n",
      "Epoch: 216, training loss: 0.12527857720851898\n",
      "Epoch: 217, training loss: 0.054529834538698196\n",
      "Epoch: 218, training loss: 0.27069926261901855\n",
      "Epoch: 219, training loss: 0.04234786704182625\n",
      "Epoch: 220, training loss: 0.1874687373638153\n",
      "Epoch: 221, training loss: 0.07278753817081451\n",
      "Epoch: 222, training loss: 0.10786624997854233\n",
      "Epoch: 223, training loss: 0.07676036655902863\n",
      "Epoch: 224, training loss: 0.04993350803852081\n",
      "Epoch: 225, training loss: 0.09025383740663528\n",
      "Epoch: 226, training loss: 0.08432899415493011\n",
      "Epoch: 227, training loss: 0.10179152339696884\n",
      "Epoch: 228, training loss: 0.22134409844875336\n",
      "Epoch: 229, training loss: 0.8762494325637817\n",
      "Epoch: 230, training loss: 0.2541205585002899\n",
      "Epoch: 231, training loss: 0.47225329279899597\n",
      "Epoch: 232, training loss: 0.08464720100164413\n",
      "Epoch: 233, training loss: 0.2213461995124817\n",
      "Epoch: 234, training loss: 0.06904902309179306\n",
      "Epoch: 235, training loss: 0.23163050413131714\n",
      "Epoch: 236, training loss: 0.6879942417144775\n",
      "Epoch: 237, training loss: 0.08348056674003601\n",
      "Epoch: 238, training loss: 0.08836539089679718\n",
      "Epoch: 239, training loss: 0.15144386887550354\n",
      "Epoch: 240, training loss: 0.05764300376176834\n",
      "Epoch: 241, training loss: 0.09804162383079529\n",
      "Epoch: 242, training loss: 0.29769575595855713\n",
      "Epoch: 243, training loss: 0.4516616463661194\n",
      "Epoch: 244, training loss: 0.16396868228912354\n",
      "Epoch: 245, training loss: 1.1308238506317139\n",
      "Epoch: 246, training loss: 4.053860187530518\n",
      "Epoch: 247, training loss: 0.15051084756851196\n",
      "Epoch: 248, training loss: 0.1339779496192932\n",
      "Epoch: 249, training loss: 0.0820818617939949\n",
      "Epoch: 250, training loss: 0.7203816771507263\n",
      "Epoch: 251, training loss: 0.11579763144254684\n",
      "Epoch: 252, training loss: 0.11966012418270111\n",
      "Epoch: 253, training loss: 0.14305950701236725\n",
      "Epoch: 254, training loss: 0.25643378496170044\n",
      "Epoch: 255, training loss: 0.20718815922737122\n",
      "Epoch: 256, training loss: 0.2377321720123291\n",
      "Epoch: 257, training loss: 0.1795622855424881\n",
      "Epoch: 258, training loss: 0.5653698444366455\n",
      "Epoch: 259, training loss: 0.2255437970161438\n",
      "Epoch: 260, training loss: 0.07356668263673782\n",
      "Epoch: 261, training loss: 0.15401512384414673\n",
      "Epoch: 262, training loss: 0.5527581572532654\n",
      "Epoch: 263, training loss: 0.31762370467185974\n",
      "Epoch: 264, training loss: 0.8289601802825928\n",
      "Epoch: 265, training loss: 0.23188279569149017\n",
      "Epoch: 266, training loss: 0.2420046478509903\n",
      "Epoch: 267, training loss: 0.26641809940338135\n",
      "Epoch: 268, training loss: 0.4657323658466339\n",
      "Epoch: 269, training loss: 0.28542643785476685\n",
      "Epoch: 270, training loss: 0.06923682242631912\n",
      "Epoch: 271, training loss: 0.06812634319067001\n",
      "Epoch: 272, training loss: 0.1078680232167244\n",
      "Epoch: 273, training loss: 0.10768970847129822\n",
      "Epoch: 274, training loss: 0.07935766875743866\n",
      "Epoch: 275, training loss: 0.0733606219291687\n",
      "Epoch: 276, training loss: 0.04828815534710884\n",
      "Epoch: 277, training loss: 0.09025392681360245\n",
      "Epoch: 278, training loss: 0.23553813993930817\n",
      "Epoch: 279, training loss: 0.15259264409542084\n",
      "Epoch: 280, training loss: 0.0934421718120575\n",
      "Epoch: 281, training loss: 0.15772944688796997\n",
      "Epoch: 282, training loss: 0.6741044521331787\n",
      "Epoch: 283, training loss: 0.12019556760787964\n",
      "Epoch: 284, training loss: 0.07713919132947922\n",
      "Epoch: 285, training loss: 0.10610951483249664\n",
      "Epoch: 286, training loss: 0.21794188022613525\n",
      "Epoch: 287, training loss: 0.12135372310876846\n",
      "Epoch: 288, training loss: 0.19194406270980835\n",
      "Epoch: 289, training loss: 0.23220564424991608\n",
      "Epoch: 290, training loss: 0.07408822327852249\n",
      "Epoch: 291, training loss: 0.12075336277484894\n",
      "Epoch: 292, training loss: 0.3716579079627991\n",
      "Epoch: 293, training loss: 0.17469248175621033\n",
      "Epoch: 294, training loss: 0.2384977489709854\n",
      "Epoch: 295, training loss: 0.07199640572071075\n",
      "Epoch: 296, training loss: 0.10202385485172272\n",
      "Epoch: 297, training loss: 0.6490597128868103\n",
      "Epoch: 298, training loss: 0.5129608511924744\n",
      "Epoch: 299, training loss: 0.09303776919841766\n",
      "Epoch: 300, training loss: 0.3607252240180969\n",
      "Epoch: 301, training loss: 0.10030718147754669\n",
      "Epoch: 302, training loss: 0.08526802808046341\n",
      "Epoch: 303, training loss: 0.13073696196079254\n",
      "Epoch: 304, training loss: 0.08991178870201111\n",
      "Epoch: 305, training loss: 4.505570888519287\n",
      "Epoch: 306, training loss: 0.06305192410945892\n",
      "Epoch: 307, training loss: 0.07716742157936096\n",
      "Epoch: 308, training loss: 0.03519056737422943\n",
      "Epoch: 309, training loss: 0.03463117405772209\n",
      "Epoch: 310, training loss: 0.09684807807207108\n",
      "Epoch: 311, training loss: 0.25456154346466064\n",
      "Epoch: 312, training loss: 0.03670688718557358\n",
      "Epoch: 313, training loss: 0.06673548370599747\n",
      "Epoch: 314, training loss: 0.5124513506889343\n",
      "Epoch: 315, training loss: 0.20055446028709412\n",
      "Epoch: 316, training loss: 0.07090417295694351\n",
      "Epoch: 317, training loss: 0.15498298406600952\n",
      "Epoch: 318, training loss: 0.16979369521141052\n",
      "Epoch: 319, training loss: 0.20266984403133392\n",
      "Epoch: 320, training loss: 0.518804669380188\n",
      "Epoch: 321, training loss: 0.10749191790819168\n",
      "Epoch: 322, training loss: 0.03315068036317825\n",
      "Epoch: 323, training loss: 0.37652987241744995\n",
      "Epoch: 324, training loss: 0.047988198697566986\n",
      "Epoch: 325, training loss: 0.059008777141571045\n",
      "Epoch: 326, training loss: 0.6119340062141418\n",
      "Epoch: 327, training loss: 0.07608215510845184\n",
      "Epoch: 328, training loss: 0.18514180183410645\n",
      "Epoch: 329, training loss: 0.11604203283786774\n",
      "Epoch: 330, training loss: 0.31738999485969543\n",
      "Epoch: 331, training loss: 0.0726759061217308\n",
      "Epoch: 332, training loss: 0.0697375163435936\n",
      "Epoch: 333, training loss: 0.044853001832962036\n",
      "Epoch: 334, training loss: 0.07028964161872864\n",
      "Epoch: 335, training loss: 0.09521182626485825\n",
      "Epoch: 336, training loss: 0.05709560215473175\n",
      "Epoch: 337, training loss: 0.08317390084266663\n",
      "Epoch: 338, training loss: 0.12291024625301361\n",
      "Epoch: 339, training loss: 0.08738045394420624\n",
      "Epoch: 340, training loss: 0.11038200557231903\n",
      "Epoch: 341, training loss: 0.072688527405262\n",
      "Epoch: 342, training loss: 0.11536748707294464\n",
      "Epoch: 343, training loss: 0.17682939767837524\n",
      "Epoch: 344, training loss: 0.24863815307617188\n",
      "Epoch: 345, training loss: 0.5289267897605896\n",
      "Epoch: 346, training loss: 0.6917366981506348\n",
      "Epoch: 347, training loss: 0.09333811700344086\n",
      "Epoch: 348, training loss: 0.13158617913722992\n",
      "Epoch: 349, training loss: 0.17229190468788147\n",
      "Epoch: 350, training loss: 0.19494719803333282\n",
      "Epoch: 351, training loss: 0.09080549329519272\n",
      "Epoch: 352, training loss: 0.13876067101955414\n",
      "Epoch: 353, training loss: 0.048503730446100235\n",
      "Epoch: 354, training loss: 0.2746855616569519\n",
      "Epoch: 355, training loss: 0.03034328669309616\n",
      "Epoch: 356, training loss: 0.09106789529323578\n",
      "Epoch: 357, training loss: 0.2102925032377243\n",
      "Epoch: 358, training loss: 0.049072954803705215\n",
      "Epoch: 359, training loss: 0.7362197041511536\n",
      "Epoch: 360, training loss: 0.07687512040138245\n",
      "Epoch: 361, training loss: 0.086698979139328\n",
      "Epoch: 362, training loss: 0.07978229224681854\n",
      "Epoch: 363, training loss: 0.04660140722990036\n",
      "Epoch: 364, training loss: 0.06152794510126114\n",
      "Epoch: 365, training loss: 0.10761015117168427\n",
      "Epoch: 366, training loss: 0.11504687368869781\n",
      "Epoch: 367, training loss: 0.04760265350341797\n",
      "Epoch: 368, training loss: 0.09534527361392975\n",
      "Epoch: 369, training loss: 0.1952766478061676\n",
      "Epoch: 370, training loss: 0.06952712684869766\n",
      "Epoch: 371, training loss: 0.040168646723032\n",
      "Epoch: 372, training loss: 0.14904442429542542\n",
      "Epoch: 373, training loss: 0.2951188087463379\n",
      "Epoch: 374, training loss: 0.13306695222854614\n",
      "Epoch: 375, training loss: 0.0951947271823883\n",
      "Epoch: 376, training loss: 0.2512591481208801\n",
      "Epoch: 377, training loss: 0.10415713489055634\n",
      "Epoch: 378, training loss: 0.047799840569496155\n",
      "Epoch: 379, training loss: 0.6672038435935974\n",
      "Epoch: 380, training loss: 0.10848033428192139\n",
      "Epoch: 381, training loss: 0.08065284788608551\n",
      "Epoch: 382, training loss: 0.379685640335083\n",
      "Epoch: 383, training loss: 0.0528571791946888\n",
      "Epoch: 384, training loss: 0.024198345839977264\n",
      "Epoch: 385, training loss: 0.13475622236728668\n",
      "Epoch: 386, training loss: 0.06515567004680634\n",
      "Epoch: 387, training loss: 0.19251376390457153\n",
      "Epoch: 388, training loss: 0.4129074215888977\n",
      "Epoch: 389, training loss: 0.3429100215435028\n",
      "Epoch: 390, training loss: 0.13896825909614563\n",
      "Epoch: 391, training loss: 0.3202846050262451\n",
      "Epoch: 392, training loss: 0.062141042202711105\n",
      "Epoch: 393, training loss: 0.0763448029756546\n",
      "Epoch: 394, training loss: 0.08825436979532242\n",
      "Epoch: 395, training loss: 0.12064336240291595\n",
      "Epoch: 396, training loss: 0.06004991754889488\n",
      "Epoch: 397, training loss: 0.14529924094676971\n",
      "Epoch: 398, training loss: 0.1125369668006897\n",
      "Epoch: 399, training loss: 0.3969932794570923\n",
      "Epoch: 400, training loss: 0.04229513183236122\n",
      "Epoch: 401, training loss: 0.2721157670021057\n",
      "Epoch: 402, training loss: 0.09838544577360153\n",
      "Epoch: 403, training loss: 0.03741796687245369\n",
      "Epoch: 404, training loss: 0.057031773030757904\n",
      "Epoch: 405, training loss: 0.3349054157733917\n",
      "Epoch: 406, training loss: 0.04114537686109543\n",
      "Epoch: 407, training loss: 0.07440182566642761\n",
      "Epoch: 408, training loss: 0.17026954889297485\n",
      "Epoch: 409, training loss: 0.18827342987060547\n",
      "Epoch: 410, training loss: 0.06181386858224869\n",
      "Epoch: 411, training loss: 0.46281713247299194\n",
      "Epoch: 412, training loss: 0.055899329483509064\n",
      "Epoch: 413, training loss: 0.25095149874687195\n",
      "Epoch: 414, training loss: 0.10210791230201721\n",
      "Epoch: 415, training loss: 0.1836220920085907\n",
      "Epoch: 416, training loss: 0.3526853621006012\n",
      "Epoch: 417, training loss: 0.6107417345046997\n",
      "Epoch: 418, training loss: 0.35425519943237305\n",
      "Epoch: 419, training loss: 0.11042250692844391\n",
      "Epoch: 420, training loss: 0.06785240769386292\n",
      "Epoch: 421, training loss: 4.0235395431518555\n",
      "Epoch: 422, training loss: 0.08757780492305756\n",
      "Epoch: 423, training loss: 0.09990069270133972\n",
      "Epoch: 424, training loss: 0.0743749588727951\n",
      "Epoch: 425, training loss: 0.03658716008067131\n",
      "Epoch: 426, training loss: 0.23554487526416779\n",
      "Epoch: 427, training loss: 0.4002240300178528\n",
      "Epoch: 428, training loss: 0.186665341258049\n",
      "Epoch: 429, training loss: 0.10984648764133453\n",
      "Epoch: 430, training loss: 0.7142040729522705\n",
      "Epoch: 431, training loss: 0.07504639774560928\n",
      "Epoch: 432, training loss: 0.05134989321231842\n",
      "Epoch: 433, training loss: 0.09002310782670975\n",
      "Epoch: 434, training loss: 0.26169952750205994\n",
      "Epoch: 435, training loss: 0.42651498317718506\n",
      "Epoch: 436, training loss: 0.050887856632471085\n",
      "Epoch: 437, training loss: 0.051806528121232986\n",
      "Epoch: 438, training loss: 0.06185908988118172\n",
      "Epoch: 439, training loss: 0.06359659135341644\n",
      "Epoch: 440, training loss: 0.07721791416406631\n",
      "Epoch: 441, training loss: 0.06168461591005325\n",
      "Epoch: 442, training loss: 0.4000788629055023\n",
      "Epoch: 443, training loss: 0.27516502141952515\n",
      "Epoch: 444, training loss: 0.04287024214863777\n",
      "Epoch: 445, training loss: 0.055928874760866165\n",
      "Epoch: 446, training loss: 0.1513315886259079\n",
      "Epoch: 447, training loss: 0.3801460564136505\n",
      "Epoch: 448, training loss: 0.14345237612724304\n",
      "Epoch: 449, training loss: 0.06080346181988716\n",
      "Epoch: 450, training loss: 0.07015808671712875\n",
      "Epoch: 451, training loss: 0.9612947702407837\n",
      "Epoch: 452, training loss: 0.05560192093253136\n",
      "Epoch: 453, training loss: 0.810935378074646\n",
      "Epoch: 454, training loss: 0.09310847520828247\n",
      "Epoch: 455, training loss: 0.12706944346427917\n",
      "Epoch: 456, training loss: 0.06292854249477386\n",
      "Epoch: 457, training loss: 0.11040899902582169\n",
      "Epoch: 458, training loss: 0.16763268411159515\n",
      "Epoch: 459, training loss: 0.21182624995708466\n",
      "Epoch: 460, training loss: 0.17863604426383972\n",
      "Epoch: 461, training loss: 0.3062433898448944\n",
      "Epoch: 462, training loss: 0.148667573928833\n",
      "Epoch: 463, training loss: 0.04766349121928215\n",
      "Epoch: 464, training loss: 0.08134592324495316\n",
      "Epoch: 465, training loss: 0.10428410023450851\n",
      "Epoch: 466, training loss: 0.10173143446445465\n",
      "Epoch: 467, training loss: 0.23791316151618958\n",
      "Epoch: 468, training loss: 0.0700022280216217\n",
      "Epoch: 469, training loss: 0.08740268647670746\n",
      "Epoch: 470, training loss: 0.1447218507528305\n",
      "Epoch: 471, training loss: 0.21700115501880646\n",
      "Epoch: 472, training loss: 0.2514016032218933\n",
      "Epoch: 473, training loss: 0.3755030333995819\n",
      "Epoch: 474, training loss: 0.17350947856903076\n",
      "Epoch: 475, training loss: 0.1602281928062439\n",
      "Epoch: 476, training loss: 0.06568333506584167\n",
      "Epoch: 477, training loss: 0.036224111914634705\n",
      "Epoch: 478, training loss: 0.31379711627960205\n",
      "Epoch: 479, training loss: 3.6934356689453125\n",
      "Epoch: 480, training loss: 0.14180076122283936\n",
      "Epoch: 481, training loss: 0.1506337821483612\n",
      "Epoch: 482, training loss: 0.11462365090847015\n",
      "Epoch: 483, training loss: 0.20598673820495605\n",
      "Epoch: 484, training loss: 0.38181132078170776\n",
      "Epoch: 485, training loss: 0.1287510097026825\n",
      "Epoch: 486, training loss: 0.3601471185684204\n",
      "Epoch: 487, training loss: 0.11636590957641602\n",
      "Epoch: 488, training loss: 0.08957234770059586\n",
      "Epoch: 489, training loss: 0.18512536585330963\n",
      "Epoch: 490, training loss: 0.04993700981140137\n",
      "Epoch: 491, training loss: 0.09560976922512054\n",
      "Epoch: 492, training loss: 0.31098610162734985\n",
      "Epoch: 493, training loss: 0.098048634827137\n",
      "Epoch: 494, training loss: 0.03443076089024544\n",
      "Epoch: 495, training loss: 0.0513182058930397\n",
      "Epoch: 496, training loss: 0.09055103361606598\n",
      "Epoch: 497, training loss: 0.07104504853487015\n",
      "Epoch: 498, training loss: 0.251727819442749\n",
      "Epoch: 499, training loss: 0.0629984438419342\n",
      "Epoch: 500, training loss: 0.413496196269989\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "opts = {\n",
    "    \"nepochs\": 500,\n",
    "    \"batch_size\": 64,\n",
    "    \"validation_period\": 1000\n",
    "}\n",
    "train_losses, val_losses = train(model, opts, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a1bf7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "52a1bf7e",
    "outputId": "6f271e1b-d65b-4fc8-b4ff-955849a1f58e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2097308b10>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphing losses\n",
    "plt.plot(np.array([x.detach().numpy() for x in train_losses]), 'r')\n",
    "plt.plot(np.array([x.detach().numpy() for x in val_losses]), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3jBqmTq_TUlT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "3jBqmTq_TUlT",
    "outputId": "ff804b21-b887-4071-9b08-5b819036883b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL PERFORMANCE - TRAINING PART\n",
    "if not model:\n",
    "  model=VolForecast(input_size=len(input_fields), seq_len=seq_len, horizon=horizon)\n",
    "  model.load_state_dict(torch.load('./model'))\n",
    "  \n",
    "plot_model_performance_single_horizon(model, train_x, train_y, num_samples=600, horizon=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "HwOpx_9ZhOH3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "HwOpx_9ZhOH3",
    "outputId": "c5d689b4-2108-48ae-c477-f6c8327a9858"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL'S PERFORMANCE - VALIDATION PART\n",
    "if not model:\n",
    "  model=VolForecast(input_size=len(input_fields), seq_len=seq_len, horizon=horizon)\n",
    "  model.load_state_dict(torch.load('./model'))\n",
    "\n",
    "plot_model_performance_single_horizon(model, val_x, val_y, num_samples=600, horizon=horizon)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
